
import { GoogleGenAI, HarmCategory, HarmBlockThreshold } from "@google/genai";
import { rateLimiter } from "./rateLimiter";
import { LineItem, RoomData, ProjectMetadata, ExtractedData, JobType } from "../types";
import { sanitizeLineItem, sortScopeItems } from "../utils/xactimateRules";
import { getSystemInstruction, buildUserPrompt } from "../utils/aiConfig";
import { enrichScopeWithLogistics } from "../utils/logisticsEngine";

const MODEL_NAME = "gemini-2.5-flash";
const API_KEY = process.env.API_KEY;

if (!API_KEY) {
  console.error("API Key is missing. Please check your .env file.");
}

// --- TEXT STREAM PARSER ---
/**
 * Parses the custom Text-Stream Protocol (META::, ROOM::, ITEM::)
 * This is robust against truncation as we can simply ignore incomplete lines.
 */
const parseTextResponse = (text: string): { rooms: RoomData[], metadata: ProjectMetadata } => {
  const lines = text.split('\n').map(l => l.trim()).filter(l => l.length > 0);
  const rooms: RoomData[] = [];
  let currentRoom: RoomData | null = null;
  
  // Default Metadata
  let metadata: ProjectMetadata = {
    loss_type_inference: "Unknown",
    severity_score: 5,
    confidence_level: "Low"
  };

  for (const line of lines) {
    try {
      if (line.startsWith('META::')) {
        const parts = line.substring(6).split('|');
        if (parts.length >= 3) {
          metadata = {
            loss_type_inference: parts[0].trim() || "Unknown",
            severity_score: parseInt(parts[1].trim()) || 5,
            confidence_level: (parts[2].trim() as any) || "Low"
          };
        }
      } else if (line.startsWith('ROOM::')) {
        const parts = line.substring(6).split('|');
        const name = parts[0]?.trim() || "Unknown Room";
        
        // Protocol V2: ROOM::Name|Timestamp|Narrative
        let timestamp = "";
        let narrative = "";

        if (parts.length >= 3) {
            timestamp = parts[1]?.trim() || "";
            narrative = parts[2]?.trim() || "";
        } else {
            // Fallback for older format or transition
            narrative = parts[1]?.trim() || "";
        }
        
        currentRoom = {
          id: crypto.randomUUID(),
          name,
          timestamp_in: timestamp, // Mapped to RoomData
          narrative_synthesis: narrative,
          flagged_issues: [],
          items: [] // Raw items, will be sorted later
        };
        rooms.push(currentRoom);
      } else if (line.startsWith('ITEM::')) {
        if (!currentRoom) continue; // Skip orphan items
        
        const parts = line.substring(6).split('|');
        // Protocol: ITEM::CAT|SEL|ACT|QTY|UNIT|CONF|DESC|REASONING
        // We need at least CAT|SEL|ACT|QTY|UNIT to be useful
        if (parts.length < 5) continue; 

        const cat = parts[0].trim();
        const sel = parts[1].trim();
        const act = parts[2].trim();
        const qtyRaw = parts[3].trim();
        const unit = parts[4].trim();
        const conf = parts[5]?.trim();
        const desc = parts[6]?.trim() || "Item description";
        const reason = parts[7]?.trim() || "Generated by AI";

        const numQty = parseFloat(qtyRaw) || 1;

        const rawItem: LineItem = {
            id: crypto.randomUUID(),
            category: cat,
            selector: sel,
            code: `${cat} ${sel}`,
            description: desc,
            activity: act,
            quantity: numQty,
            quantity_inference: qtyRaw,
            unit: unit,
            reasoning: reason,
            confidence: (conf as any) || 'Low'
        };
        
        // Apply Sanitization immediately
        currentRoom.items.push(sanitizeLineItem(rawItem));
      }
    } catch (e) {
      console.warn("Skipping malformed line:", line, e);
      // Continue to next line - strict fault tolerance
    }
  }

  // Final Sort per room
  rooms.forEach(r => {
      r.items = sortScopeItems(r.items);
  });

  return { rooms, metadata };
};

export const generateScope = async (
  description: string,
  scopeContext: string,
  jobType: JobType, // Changed from scopePhase to JobType
  base64Images: string[] = [],
  videoData?: ExtractedData | null
): Promise<{ rooms: RoomData[], metadata: ProjectMetadata }> => {
  return rateLimiter.enqueue(async () => {
    const ai = new GoogleGenAI({ apiKey: API_KEY });
    
    // Map Job Type to Scope Phase for Logic Gates
    const scopePhase = jobType === 'R' ? 'reconstruction' : 'mitigation';
    
    const parts: any[] = [{ text: buildUserPrompt(`${description} [Scope Context: ${scopeContext}]`, jobType) }];

    // 1. Handle Extracted Video Data
    if (videoData) {
      if (videoData.audio) {
        parts.push({
          inlineData: {
            mimeType: "audio/wav",
            data: videoData.audio
          }
        });
      }
      videoData.frames.forEach(frameBase64 => {
        parts.push({
          inlineData: {
            mimeType: "image/jpeg",
            data: frameBase64
          }
        });
      });
    }

    // 2. Handle Standard Images
    base64Images.forEach(img => {
      const data = img.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "");
      parts.push({
        inlineData: {
          mimeType: "image/jpeg",
          data: data
        }
      });
    });

    // 3. Call Gemini
    try {
      const response = await ai.models.generateContent({
        model: MODEL_NAME,
        contents: { parts },
        config: {
          systemInstruction: getSystemInstruction(scopePhase), // DYNAMIC INSTRUCTION
          responseMimeType: "text/plain",
          temperature: 0.1,
          maxOutputTokens: 8192,
          safetySettings: [
            { category: HarmCategory.HARM_CATEGORY_HATE_SPEECH, threshold: HarmBlockThreshold.BLOCK_NONE },
            { category: HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT, threshold: HarmBlockThreshold.BLOCK_NONE },
            { category: HarmCategory.HARM_CATEGORY_HARASSMENT, threshold: HarmBlockThreshold.BLOCK_NONE },
            { category: HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT, threshold: HarmBlockThreshold.BLOCK_NONE },
          ]
        }
      });

      const candidate = response.candidates?.[0];
      
      // 4. AGGRESSIVE TEXT EXTRACTION
      let rawText = "";
      try {
        if (response.text) {
          rawText = response.text;
        }
      } catch (e) {
         // Fallback
      }

      if ((!rawText || candidate?.finishReason === 'MAX_TOKENS') && candidate?.content?.parts) {
        console.warn("⚠️ Attempting manual extraction/salvage...");
        rawText = candidate.content.parts
          .map((p: any) => p.text || '')
          .join('');
      }

      if (!rawText) {
        throw new Error(`Empty response from AI. Finish Reason: ${candidate?.finishReason || 'Unknown'}`);
      }

      if (candidate?.finishReason === 'MAX_TOKENS') {
        console.warn("⚠️ Response truncated. Parsing partial stream.");
      }

      // 5. Parse Text Protocol
      const parsedResult = parseTextResponse(rawText);

      // 6. LOGISTICS ENGINE ENRICHMENT
      parsedResult.rooms = enrichScopeWithLogistics(
        parsedResult.rooms, 
        parsedResult.metadata.severity_score, 
        scopeContext,
        parsedResult.metadata.loss_type_inference
      );

      return parsedResult;

    } catch (error) {
      console.error("Gemini Core Engine Error:", error);
      throw error;
    }
  });
};
